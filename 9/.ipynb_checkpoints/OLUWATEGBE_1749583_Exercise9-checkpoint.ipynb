{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca289bb4-bda2-47eb-a2fd-1cdc8a0acbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c24ea4c-f7df-4bba-b65c-9a66ce642163",
   "metadata": {},
   "source": [
    "### 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c04a0a7b-e77d-44e0-bbb2-4bbdb3f8a5d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Basket_ID</th>\n",
       "      <th>Items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>bread, eggs, milk, cheese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>beer, cheese, milk, diapers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>milk, cheese, beer, bread, diapers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>eggs, butter, bread</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>bread, diapers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Basket_ID                               Items\n",
       "0          1           bread, eggs, milk, cheese\n",
       "1          2         beer, cheese, milk, diapers\n",
       "2          3  milk, cheese, beer, bread, diapers\n",
       "3          4                 eggs, butter, bread\n",
       "4          5                      bread, diapers"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('basket.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8a109f47-b56c-46c8-a240-6b27a24a02c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from collections import defaultdict\n",
    "\n",
    "df['Items'] = df['Items'].apply(lambda x: set(x.split(', ')))\n",
    "transactions = df['Items'].tolist()\n",
    "\n",
    "# Calculating frequency and support for single-item itemsets\n",
    "item_counts = defaultdict(int)\n",
    "num_transactions = len(transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "080e9ce3-8cae-41a9-8f9f-6a223deefc2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'bread', 'cheese', 'eggs', 'milk'},\n",
       " {'beer', 'cheese', 'diapers', 'milk'},\n",
       " {'beer', 'bread', 'cheese', 'diapers', 'milk'},\n",
       " {'bread', 'butter', 'eggs'},\n",
       " {'bread', 'diapers'},\n",
       " {'bread', 'diapers', 'milk'},\n",
       " {'beer', 'bread', 'cheese', 'diapers', 'eggs'},\n",
       " {'butter', 'diapers'},\n",
       " {'beer', 'butter', 'cheese'},\n",
       " {'bread', 'cheese', 'eggs', 'milk'},\n",
       " {'butter', 'diapers', 'milk'},\n",
       " {'butter', 'diapers', 'eggs', 'milk'},\n",
       " {'beer', 'bread', 'butter', 'diapers', 'milk'},\n",
       " {'butter', 'milk'},\n",
       " {'bread', 'butter', 'diapers', 'eggs', 'milk'},\n",
       " {'bread', 'butter'},\n",
       " {'beer', 'bread', 'diapers', 'eggs', 'milk'},\n",
       " {'beer', 'milk'},\n",
       " {'beer', 'bread', 'butter', 'diapers', 'eggs'},\n",
       " {'beer', 'bread', 'butter', 'milk'},\n",
       " {'beer', 'bread', 'cheese', 'eggs'},\n",
       " {'beer', 'eggs'},\n",
       " {'cheese', 'eggs', 'milk'},\n",
       " {'bread', 'butter', 'cheese', 'eggs'},\n",
       " {'beer', 'bread', 'eggs', 'milk'},\n",
       " {'bread', 'diapers', 'eggs', 'milk'},\n",
       " {'bread', 'butter', 'cheese'},\n",
       " {'butter', 'cheese', 'diapers', 'eggs'},\n",
       " {'bread', 'eggs'},\n",
       " {'beer', 'bread', 'diapers', 'milk'}]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3973b95-6b55-4e59-8ca4-62f313531dcd",
   "metadata": {},
   "source": [
    "#### Frequency of each itemset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1fa8d5a0-0844-45b7-9ebd-610ea4501e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'eggs': 16,\n",
       "             'cheese': 11,\n",
       "             'milk': 17,\n",
       "             'bread': 20,\n",
       "             'diapers': 15,\n",
       "             'beer': 13,\n",
       "             'butter': 14})"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for transaction in transactions:\n",
    "    for item in transaction:\n",
    "        item_counts[item] += 1\n",
    "item_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66835b16-4a0d-410d-9ae7-eed331f643d9",
   "metadata": {},
   "source": [
    "#### Support of each itemset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e42502b5-7071-44d8-9a24-e5e447bfbd27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eggs': 0.5333333333333333,\n",
       " 'cheese': 0.36666666666666664,\n",
       " 'milk': 0.5666666666666667,\n",
       " 'bread': 0.6666666666666666,\n",
       " 'diapers': 0.5,\n",
       " 'beer': 0.43333333333333335,\n",
       " 'butter': 0.4666666666666667}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_support = {item: count / num_transactions for item, count in item_counts.items()}\n",
    "item_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ff168916-2468-431a-b37a-27806a1594dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules_association = []\n",
    "for item1, item2 in combinations(item_counts.keys(), 2):\n",
    "    \n",
    "    supportitem_1 = item_support[item1]      # the support of individual items and pair\n",
    "    supportitem_2 = item_support[item2]\n",
    "    \n",
    "    pair_count = sum(1 for transaction in transactions if {item1, item2}.issubset(transaction))  # the frequency and support of the chosen pair\n",
    "    support_pair = pair_count / num_transactions\n",
    "\n",
    "    if pair_count > 0:\n",
    "       \n",
    "        confidence1_to_2 = support_pair / supportitem_1  # Confidence is gotten from pairsupport(item2 | item1) and pairsupport(item1 | item2)\n",
    "        confidence2_to_1 = support_pair / supportitem_2\n",
    "\n",
    "        lift1_to_2 = confidence1_to_2 / supportitem_2   \n",
    "        lift2_to_1 = confidence2_to_1 / supportitem_1\n",
    "\n",
    "\n",
    "        rules_association.append((item1, item2, pair_count, support_pair, confidence1_to_2, lift1_to_2))\n",
    "        rules_association.append((item2, item1, pair_count, support_pair, confidence2_to_1, lift2_to_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b32ecd3a-7b57-4f1a-a6ba-16c9e69b1e77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eggs</td>\n",
       "      <td>16</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cheese</td>\n",
       "      <td>11</td>\n",
       "      <td>0.366667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>milk</td>\n",
       "      <td>17</td>\n",
       "      <td>0.566667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bread</td>\n",
       "      <td>20</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>diapers</td>\n",
       "      <td>15</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>beer</td>\n",
       "      <td>13</td>\n",
       "      <td>0.433333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>butter</td>\n",
       "      <td>14</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Item  Frequency   Support\n",
       "0     eggs         16  0.533333\n",
       "1   cheese         11  0.366667\n",
       "2     milk         17  0.566667\n",
       "3    bread         20  0.666667\n",
       "4  diapers         15  0.500000\n",
       "5     beer         13  0.433333\n",
       "6   butter         14  0.466667"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare data for reporting\n",
    "frequencies = pd.DataFrame({'Item': item_counts.keys(), 'Frequency': item_counts.values()})\n",
    "frequencies['Support'] = frequencies['Item'].map(item_support)\n",
    "rules_df = pd.DataFrame(rules_association, columns=[\n",
    "    'Item1', 'Item2', 'Pair_Count', 'Support Pair', 'Confidence', 'Lift'\n",
    "])\n",
    "frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "38856e84-0ba0-4913-a4f5-50b9c7f796fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item1</th>\n",
       "      <th>Item2</th>\n",
       "      <th>Pair_Count</th>\n",
       "      <th>Support Pair</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>Lift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eggs</td>\n",
       "      <td>cheese</td>\n",
       "      <td>7</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>1.193182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cheese</td>\n",
       "      <td>eggs</td>\n",
       "      <td>7</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>1.193182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eggs</td>\n",
       "      <td>milk</td>\n",
       "      <td>8</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.882353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>milk</td>\n",
       "      <td>eggs</td>\n",
       "      <td>8</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.882353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eggs</td>\n",
       "      <td>bread</td>\n",
       "      <td>12</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.125000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Item1   Item2  Pair_Count  Support Pair  Confidence      Lift\n",
       "0    eggs  cheese           7      0.233333    0.437500  1.193182\n",
       "1  cheese    eggs           7      0.233333    0.636364  1.193182\n",
       "2    eggs    milk           8      0.266667    0.500000  0.882353\n",
       "3    milk    eggs           8      0.266667    0.470588  0.882353\n",
       "4    eggs   bread          12      0.400000    0.750000  1.125000"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d1bbe8-3065-4451-8f74-8f35c6b36f2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfa7bf5-0190-4cb2-9999-665791b9e94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### MBA analysis, not apriori\n",
    "\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"/mnt/data/basket.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "df.head()\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "# Convert the 'Items' column into a list of sets\n",
    "df['Items'] = df['Items'].apply(lambda x: set(x.split(', ')))\n",
    "\n",
    "# Create a list of all unique items\n",
    "all_items = set(item for sublist in df['Items'] for item in sublist)\n",
    "\n",
    "# Compute item frequencies\n",
    "item_frequencies = defaultdict(int)\n",
    "for items in df['Items']:\n",
    "    for item in items:\n",
    "        item_frequencies[item] += 1\n",
    "\n",
    "# Convert to DataFrame for better visualization\n",
    "item_freq_df = pd.DataFrame(item_frequencies.items(), columns=['Item', 'Frequency'])\n",
    "item_freq_df = item_freq_df.sort_values(by='Frequency', ascending=False)\n",
    "\n",
    "# Display the frequency of each itemset\n",
    "import ace_tools as tools\n",
    "tools.display_dataframe_to_user(name=\"Item Frequency\", dataframe=item_freq_df)\n",
    "\n",
    "\n",
    "# Compute Support of each item\n",
    "total_transactions = len(df)\n",
    "\n",
    "# Calculate support for each item\n",
    "item_support = {item: freq / total_transactions for item, freq in item_frequencies.items()}\n",
    "\n",
    "# Convert to DataFrame for better visualization\n",
    "item_support_df = pd.DataFrame(item_support.items(), columns=['Item', 'Support'])\n",
    "item_support_df = item_support_df.sort_values(by='Support', ascending=False)\n",
    "\n",
    "# Display the support of each itemset\n",
    "tools.display_dataframe_to_user(name=\"Item Support\", dataframe=item_support_df)\n",
    "\n",
    "\n",
    "# Generate all possible item pairs for association rules\n",
    "pair_frequencies = defaultdict(int)\n",
    "for items in df['Items']:\n",
    "    for pair in combinations(items, 2):\n",
    "        pair_frequencies[pair] += 1\n",
    "\n",
    "# Compute confidence and lift for association rules\n",
    "association_rules = []\n",
    "for (A, B), freq_AB in pair_frequencies.items():\n",
    "    support_AB = freq_AB / total_transactions\n",
    "    confidence_A_to_B = support_AB / item_support[A]\n",
    "    confidence_B_to_A = support_AB / item_support[B]\n",
    "    lift_A_to_B = confidence_A_to_B / item_support[B]\n",
    "    lift_B_to_A = confidence_B_to_A / item_support[A]\n",
    "\n",
    "    association_rules.append([A, B, support_AB, confidence_A_to_B, lift_A_to_B])\n",
    "    association_rules.append([B, A, support_AB, confidence_B_to_A, lift_B_to_A])\n",
    "\n",
    "# Convert to DataFrame for better visualization\n",
    "association_rules_df = pd.DataFrame(association_rules, columns=['Antecedent', 'Consequent', 'Support', 'Confidence', 'Lift'])\n",
    "association_rules_df = association_rules_df.sort_values(by='Lift', ascending=False)\n",
    "\n",
    "# Display the association rules with confidence and lift\n",
    "tools.display_dataframe_to_user(name=\"Association Rules\", dataframe=association_rules_df)\n",
    "\n",
    "\n",
    "\n",
    "########## with libraries\n",
    "\n",
    "# Convert the dataset into a binary transaction matrix\n",
    "encoded_items = df['Items'].apply(lambda x: {item: 1 for item in x}).tolist()\n",
    "encoded_df = pd.DataFrame(encoded_items).fillna(0).astype(int)\n",
    "\n",
    "# Compute frequent itemsets using a minimum support threshold of 0.1\n",
    "min_support = 0.1\n",
    "total_transactions = len(encoded_df)\n",
    "item_supports = encoded_df.mean()\n",
    "\n",
    "frequent_items = item_supports[item_supports >= min_support].reset_index()\n",
    "frequent_items.columns = ['Item', 'Support']\n",
    "\n",
    "# Display the frequent itemsets\n",
    "tools.display_dataframe_to_user(name=\"Frequent Itemsets\", dataframe=frequent_items)\n",
    "\n",
    "# Compute association rules\n",
    "association_rules_list = []\n",
    "for (A, B) in combinations(frequent_items['Item'], 2):\n",
    "    support_A = item_supports[A]\n",
    "    support_B = item_supports[B]\n",
    "    support_AB = (encoded_df[A] & encoded_df[B]).mean()\n",
    "    \n",
    "    if support_AB >= min_support:\n",
    "        confidence_A_to_B = support_AB / support_A\n",
    "        confidence_B_to_A = support_AB / support_B\n",
    "        lift_A_to_B = confidence_A_to_B / support_B\n",
    "        lift_B_to_A = confidence_B_to_A / support_A\n",
    "\n",
    "        association_rules_list.append([A, B, support_AB, confidence_A_to_B, lift_A_to_B])\n",
    "        association_rules_list.append([B, A, support_AB, confidence_B_to_A, lift_B_to_A])\n",
    "\n",
    "# Convert to DataFrame\n",
    "association_rules_df = pd.DataFrame(association_rules_list, columns=['Antecedent', 'Consequent', 'Support', 'Confidence', 'Lift'])\n",
    "association_rules_df = association_rules_df.sort_values(by='Lift', ascending=False)\n",
    "\n",
    "# Display the association rules\n",
    "tools.display_dataframe_to_user(name=\"Association Rules\", dataframe=association_rules_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f67a33-aac9-449c-a888-db1d62554763",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c10d69c-353c-4d92-824a-884fd4b104c8",
   "metadata": {},
   "source": [
    "### 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00d4418-4aad-4990-9a47-6d13764a1284",
   "metadata": {},
   "source": [
    "#### Apriori algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "28baa57a-1920-4820-a8ba-1b955ab2335b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shrimp</th>\n",
       "      <th>almonds</th>\n",
       "      <th>avocado</th>\n",
       "      <th>vegetables mix</th>\n",
       "      <th>green grapes</th>\n",
       "      <th>whole weat flour</th>\n",
       "      <th>yams</th>\n",
       "      <th>cottage cheese</th>\n",
       "      <th>energy drink</th>\n",
       "      <th>tomato juice</th>\n",
       "      <th>low fat yogurt</th>\n",
       "      <th>green tea</th>\n",
       "      <th>honey</th>\n",
       "      <th>salad</th>\n",
       "      <th>mineral water</th>\n",
       "      <th>salmon</th>\n",
       "      <th>antioxydant juice</th>\n",
       "      <th>frozen smoothie</th>\n",
       "      <th>spinach</th>\n",
       "      <th>olive oil</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>burgers</td>\n",
       "      <td>meatballs</td>\n",
       "      <td>eggs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chutney</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>turkey</td>\n",
       "      <td>avocado</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mineral water</td>\n",
       "      <td>milk</td>\n",
       "      <td>energy bar</td>\n",
       "      <td>whole wheat rice</td>\n",
       "      <td>green tea</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>low fat yogurt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           shrimp    almonds     avocado    vegetables mix green grapes  \\\n",
       "0         burgers  meatballs        eggs               NaN          NaN   \n",
       "1         chutney        NaN         NaN               NaN          NaN   \n",
       "2          turkey    avocado         NaN               NaN          NaN   \n",
       "3   mineral water       milk  energy bar  whole wheat rice    green tea   \n",
       "4  low fat yogurt        NaN         NaN               NaN          NaN   \n",
       "\n",
       "  whole weat flour yams cottage cheese energy drink tomato juice  \\\n",
       "0              NaN  NaN            NaN          NaN          NaN   \n",
       "1              NaN  NaN            NaN          NaN          NaN   \n",
       "2              NaN  NaN            NaN          NaN          NaN   \n",
       "3              NaN  NaN            NaN          NaN          NaN   \n",
       "4              NaN  NaN            NaN          NaN          NaN   \n",
       "\n",
       "  low fat yogurt green tea honey salad mineral water salmon antioxydant juice  \\\n",
       "0            NaN       NaN   NaN   NaN           NaN    NaN               NaN   \n",
       "1            NaN       NaN   NaN   NaN           NaN    NaN               NaN   \n",
       "2            NaN       NaN   NaN   NaN           NaN    NaN               NaN   \n",
       "3            NaN       NaN   NaN   NaN           NaN    NaN               NaN   \n",
       "4            NaN       NaN   NaN   NaN           NaN    NaN               NaN   \n",
       "\n",
       "  frozen smoothie spinach  olive oil  \n",
       "0             NaN     NaN        NaN  \n",
       "1             NaN     NaN        NaN  \n",
       "2             NaN     NaN        NaN  \n",
       "3             NaN     NaN        NaN  \n",
       "4             NaN     NaN        NaN  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('Market_Basket_Optimisation.csv')\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "18b4fc8f-e314-41f6-9b9f-5d38169749e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = df1.apply(lambda row: row.dropna().tolist(), axis=1).tolist()\n",
    "\n",
    "def apriori(transactions, min_support):\n",
    "    def get_support_count(itemsets, transactions):\n",
    "        support_counts = defaultdict(int)  #Calculating support count for each itemset\n",
    "        for transaction in transactions:\n",
    "            for item in itemsets:\n",
    "                if item.issubset(transaction):\n",
    "                    support_counts[item] += 1\n",
    "        return support_counts\n",
    "\n",
    "    single_items = {frozenset([item]) for transaction in transactions for item in transaction}\n",
    "    #print(single_items)\n",
    "    #single_items = {item for transaction in transactions for item in transaction}\n",
    "    support_counts = get_support_count(single_items, transactions)\n",
    "    #print(support_counts)\n",
    "    \n",
    "    frequent_items = {itemset: count for itemset, count in support_counts.items() \n",
    "                         if count / len(transactions) >= min_support}   #using the minimum support to filter..\n",
    "    \n",
    "    k = 2\n",
    "    all_frequent_itemsets = [frequent_items]\n",
    "    while frequent_items:\n",
    "        candidates = set(\n",
    "            [frozenset(item1.union(item2)) for item1 in frequent_items\n",
    "             for item2 in frequent_items if len(item1.union(item2)) == k]\n",
    "        )\n",
    "        support_counts = get_support_count(candidates, transactions)\n",
    "        frequent_items = {itemset: count for itemset, count in support_counts.items() \n",
    "                             if count / len(transactions) >= min_support}\n",
    "        \n",
    "        if frequent_itemsets:\n",
    "            all_frequent_itemsets.append(frequent_items)\n",
    "        \n",
    "        k += 1\n",
    "    \n",
    "    return all_frequent_itemsets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4aec2f8f-d9eb-4655-b86a-20cd1f494d6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['burgers', 'meatballs', 'eggs'],\n",
       " ['chutney'],\n",
       " ['turkey', 'avocado'],\n",
       " ['mineral water', 'milk', 'energy bar', 'whole wheat rice', 'green tea'],\n",
       " ['low fat yogurt'],\n",
       " ['whole wheat pasta', 'french fries'],\n",
       " ['soup', 'light cream', 'shallot'],\n",
       " ['frozen vegetables', 'spaghetti', 'green tea'],\n",
       " ['french fries'],\n",
       " ['eggs', 'pet food']]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9b8d0e27-88cf-4ee9-bef0-76b195b036e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'burgers'},\n",
       " {'burgers', 'eggs'},\n",
       " {'burgers', 'mineral water'},\n",
       " {'burgers', 'french fries'},\n",
       " {'burgers', 'spaghetti'},\n",
       " {'meatballs'},\n",
       " {'eggs'},\n",
       " {'eggs', 'mineral water'},\n",
       " {'eggs', 'milk'},\n",
       " {'eggs', 'green tea'}]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_support = 0.02 \n",
    "frequent_itemsets = apriori(transactions, min_support)\n",
    "frequent_itemsets_cleaned[:10]\n",
    "\n",
    "# frequent_itemsets_cleaned = [\n",
    "#     {tuple(sorted(itemset)): count for itemset, count in level.items()}\n",
    "#     for level in frequent_itemsets\n",
    "# ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc82f75-87f3-4def-b9f8-7ea876aad07d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae5e23ea-f560-4004-b66e-ed5f82baa66d",
   "metadata": {},
   "source": [
    "#### Improved Apriori algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "218ada6c-22a9-47a8-be6e-d1da618f98ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(frozenset({'burgers'}), 654),\n",
       " (frozenset({'meatballs'}), 157),\n",
       " (frozenset({'eggs'}), 1348),\n",
       " (frozenset({'turkey'}), 469),\n",
       " (frozenset({'avocado'}), 249),\n",
       " (frozenset({'mineral water'}), 1787),\n",
       " (frozenset({'milk'}), 972),\n",
       " (frozenset({'energy bar'}), 203),\n",
       " (frozenset({'whole wheat rice'}), 439),\n",
       " (frozenset({'green tea'}), 990)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def improved_apriori(transactions, min_support):\n",
    "\n",
    "    item_support = defaultdict(int)\n",
    "    total_transactions = len(transactions)\n",
    "    min_support_count = min_support * total_transactions\n",
    "\n",
    "    for transaction in transactions:\n",
    "        for item in transaction:\n",
    "            item_support[frozenset([item])] += 1\n",
    "\n",
    "    current_itemsets = {itemset: count for itemset, count in item_support.items() if count >= min_support_count} #removing 1 itemsets\n",
    "    frequent_itemsets = list(current_itemsets.items())\n",
    "\n",
    "    k = 2\n",
    "    while current_itemsets:\n",
    "        candidate_support = defaultdict(int)\n",
    "        current_items = list(current_itemsets.keys())\n",
    "\n",
    "        for i in range(len(current_items)):\n",
    "            for j in range(i + 1, len(current_items)):\n",
    "                candidate = current_items[i] | current_items[j]\n",
    "                if len(candidate) == k:\n",
    "                    for transaction in transactions:\n",
    "                        if candidate.issubset(transaction):\n",
    "                            candidate_support[candidate] += 1\n",
    "\n",
    "        # remove the non-frequent candidates\n",
    "        current_itemsets = {itemset: count for itemset, count in candidate_support.items() if count >= min_support_count}\n",
    "        frequent_itemsets.extend(current_itemsets.items())\n",
    "\n",
    "        k += 1\n",
    "\n",
    "    return frequent_itemsets\n",
    "\n",
    "\n",
    "frequent_itemsets_improved = improved_apriori(transactions, min_support)\n",
    "frequent_itemsets_improved[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "08c8e095-7b3f-401f-be05-46160ae94e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(frozenset({'burgers'}), frozenset({'eggs'}), 0.3302752293577982),\n",
       " (frozenset({'milk'}), frozenset({'mineral water'}), 0.37037037037037035),\n",
       " (frozenset({'whole wheat rice'}),\n",
       "  frozenset({'mineral water'}),\n",
       "  0.3439635535307517),\n",
       " (frozenset({'low fat yogurt'}),\n",
       "  frozenset({'mineral water'}),\n",
       "  0.31239092495637),\n",
       " (frozenset({'soup'}), frozenset({'mineral water'}), 0.45646437994722955),\n",
       " (frozenset({'frozen vegetables'}),\n",
       "  frozenset({'mineral water'}),\n",
       "  0.3748251748251748),\n",
       " (frozenset({'spaghetti'}), frozenset({'mineral water'}), 0.3430321592649311),\n",
       " (frozenset({'cooking oil'}),\n",
       "  frozenset({'mineral water'}),\n",
       "  0.39425587467362927),\n",
       " (frozenset({'shrimp'}), frozenset({'mineral water'}), 0.32897196261682243),\n",
       " (frozenset({'chocolate'}), frozenset({'mineral water'}), 0.32113821138211385)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_association_rules(frequent_itemsets, min_confidence):\n",
    "    rules = []\n",
    "    itemset_support = {itemset: support for itemset, support in frequent_itemsets}\n",
    "\n",
    "    for itemset, support in frequent_itemsets:\n",
    "        if len(itemset) > 1:\n",
    "            for item in map(frozenset, combinations(itemset, len(itemset) - 1)):\n",
    "                consequent = itemset - item\n",
    "                if consequent and item in itemset_support:\n",
    "                    confidence = support / itemset_support[item]\n",
    "                    if confidence >= min_confidence:\n",
    "                        rules.append((item, consequent, confidence))\n",
    "    return rules\n",
    "\n",
    "\n",
    "min_conf = 0.3\n",
    "association_rules = generate_association_rules(frequent_itemsets_improved, min_conf)\n",
    "association_rules[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2176182a-634e-4121-a115-c92cc16d123d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb19ceb-083a-43a7-9f75-dd1c2f071acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "######## apriori manualy\n",
    "from collections import defaultdict\n",
    "\n",
    "# Convert dataset into a list of sets for easier processing\n",
    "transactions_new = df_new.apply(lambda row: set(row.dropna()), axis=1).tolist()\n",
    "\n",
    "# Compute individual item frequencies\n",
    "item_counts = defaultdict(int)\n",
    "for transaction in transactions_new:\n",
    "    for item in transaction:\n",
    "        item_counts[item] += 1\n",
    "\n",
    "# Calculate support for individual items\n",
    "total_transactions_new = len(transactions_new)\n",
    "min_support = 0.05  # Minimum support threshold\n",
    "\n",
    "item_supports = {item: count / total_transactions_new for item, count in item_counts.items() if count / total_transactions_new >= min_support}\n",
    "\n",
    "# Convert to DataFrame\n",
    "frequent_items_df = pd.DataFrame(item_supports.items(), columns=['Item', 'Support'])\n",
    "frequent_items_df = frequent_items_df.sort_values(by='Support', ascending=False)\n",
    "\n",
    "# Display the frequent itemsets\n",
    "tools.display_dataframe_to_user(name=\"Frequent Itemsets (Manual Apriori)\", dataframe=frequent_items_df)\n",
    "\n",
    "# Compute association rules\n",
    "association_rules_list = []\n",
    "for (A, B) in combinations(item_supports.keys(), 2):\n",
    "    support_A = item_supports[A]\n",
    "    support_B = item_supports[B]\n",
    "    support_AB = sum(1 for t in transactions_new if A in t and B in t) / total_transactions_new\n",
    "\n",
    "    if support_AB >= min_support:\n",
    "        confidence_A_to_B = support_AB / support_A\n",
    "        confidence_B_to_A = support_AB / support_B\n",
    "        lift_A_to_B = confidence_A_to_B / support_B\n",
    "        lift_B_to_A = confidence_B_to_A / support_A\n",
    "\n",
    "        association_rules_list.append([A, B, support_AB, confidence_A_to_B, lift_A_to_B])\n",
    "        association_rules_list.append([B, A, support_AB, confidence_B_to_A, lift_B_to_A])\n",
    "\n",
    "# Convert to DataFrame\n",
    "association_rules_df_new = pd.DataFrame(association_rules_list, columns=['Antecedent', 'Consequent', 'Support', 'Confidence', 'Lift'])\n",
    "association_rules_df_new = association_rules_df_new.sort_values(by='Lift', ascending=False)\n",
    "\n",
    "# Display the association rules\n",
    "tools.display_dataframe_to_user(name=\"Association Rules (Manual Apriori)\", dataframe=association_rules_df_new)\n",
    "\n",
    "\n",
    "####### apriri with libraries\n",
    "\n",
    "pip install mlxtend\n",
    "\n",
    "\n",
    "# Attempting to use the `mlxtend` library again for Apriori implementation\n",
    "try:\n",
    "    from mlxtend.frequent_patterns import apriori, association_rules\n",
    "    from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "    # Convert the dataset into a list of transactions\n",
    "    transactions_new = df_new.apply(lambda row: [item for item in row if isinstance(item, str)], axis=1).tolist()\n",
    "\n",
    "    # Transform the dataset using TransactionEncoder\n",
    "    te = TransactionEncoder()\n",
    "    te_ary = te.fit(transactions_new).transform(transactions_new)\n",
    "    df_encoded_new = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "    # Apply Apriori algorithm to find frequent itemsets with a minimum support of 0.05\n",
    "    frequent_itemsets_new = apriori(df_encoded_new, min_support=0.05, use_colnames=True)\n",
    "\n",
    "    # Generate association rules based on lift\n",
    "    rules_new = association_rules(frequent_itemsets_new, metric=\"lift\", min_threshold=1.0)\n",
    "\n",
    "    # Display the frequent itemsets\n",
    "    tools.display_dataframe_to_user(name=\"Frequent Itemsets (Apriori)\", dataframe=frequent_itemsets_new)\n",
    "\n",
    "    # Display the association rules\n",
    "    tools.display_dataframe_to_user(name=\"Association Rules (Apriori)\", dataframe=rules_new)\n",
    "\n",
    "except ModuleNotFoundError:\n",
    "    print(\"The `mlxtend` library is not available in this environment. Please install it using `pip install mlxtend`.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d5bd82-3317-4c3d-97aa-601901a17a79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609a784a-859e-4ac0-9094-7f5c8ecbea0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "00ad9313-228c-4473-ade3-923846b3d6d1",
   "metadata": {},
   "source": [
    "### 3) Eclat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9de9ebac-9309-4249-aba0-5a162164166b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vert_data(transactions):\n",
    "    vertical_data = defaultdict(set)\n",
    "    for tid, transaction in enumerate(transactions):\n",
    "        for item in transaction:\n",
    "            vertical_data[item].add(tid)\n",
    "    return vertical_data\n",
    "\n",
    "\n",
    "def eclat(prefix, items, vertical_data, min_support_count, frequent_itemsets):\n",
    "    while items:\n",
    "        item = items.pop()\n",
    "        new_prefix = prefix | {item}\n",
    "        tid_set = vertical_data[item]\n",
    "        \n",
    "        support = len(tid_set)\n",
    "        if support >= min_support_count:\n",
    "            frequent_itemsets.append((new_prefix, support))\n",
    "            new_items = [i for i in items if len(tid_set & vertical_data[i]) >= min_support_count]  # Generating new itemsets\n",
    "            new_vertical_data = {i: tid_set & vertical_data[i] for i in new_items}\n",
    "            eclat(new_prefix, new_items, new_vertical_data, min_support_count, frequent_itemsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "85e03778-1321-494b-9b41-40085b9bdfea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'ham'}, 199),\n",
       " ({'champagne'}, 351),\n",
       " ({'milk'}, 972),\n",
       " ({'ground beef', 'milk'}, 165),\n",
       " ({'milk', 'mineral water'}, 360),\n",
       " ({'milk', 'spaghetti'}, 266),\n",
       " ({'french fries', 'milk'}, 178),\n",
       " ({'eggs', 'milk'}, 231),\n",
       " ({'chocolate', 'milk'}, 241),\n",
       " ({'frozen vegetables', 'milk'}, 177)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def eclat_run(transactions, min_support):\n",
    "    total_transactions = len(transactions)\n",
    "    min_support_count = min_support * total_transactions\n",
    "    vertical_data = build_vert_data(transactions)\n",
    "    frequent_itemsets = []\n",
    "    J = set(vertical_data.keys())\n",
    "    eclat(set(), J, vertical_data, min_support_count, frequent_itemsets)\n",
    "    return frequent_itemsets\n",
    "\n",
    "frequent_itemsets = eclat_run(transactions, min_support)\n",
    "frequent_itemsets[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5774288-a1a7-4145-8ef7-13eb8baeeecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "association_rules_eclat = generate_association_rules(frequent_itemsets_eclat, min_confidence)\n",
    "association_rules_eclat[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c9535966-4701-486e-914a-dee3b0405156",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Convert transactions into vertical format\n",
    "def create_vertical_format(transactions):\n",
    "    item_tids = defaultdict(set)\n",
    "    for tid, transaction in enumerate(transactions):\n",
    "        for item in transaction:\n",
    "            item_tids[item].add(tid)\n",
    "    return item_tids\n",
    "\n",
    "# Eclat algorithm to find frequent itemsets\n",
    "def eclat(transactions, min_support):\n",
    "    # Convert transactions to vertical format\n",
    "    item_tids = create_vertical_format(transactions)\n",
    "   # print(item_tids)\n",
    "    n_transactions = len(transactions)\n",
    "    frequent_itemsets = []\n",
    "    \n",
    "    # Function to calculate support based on TID sets\n",
    "    def get_support(tid_set):\n",
    "        return len(tid_set) / n_transactions\n",
    "    \n",
    "    # Depth-first search (DFS) style function to mine itemsets\n",
    "    def dfs(prefix, items, k):\n",
    "        for item, tids in items.items():\n",
    "            # Create a new itemset by combining the current prefix with the new item\n",
    "            new_itemset = prefix | {item}\n",
    "            support = get_support(tids)\n",
    "            \n",
    "            # If the support of the new itemset meets the threshold, add it to the frequent itemsets\n",
    "            if support >= min_support:\n",
    "                frequent_itemsets.append((new_itemset, support))\n",
    "                \n",
    "                # Recursively mine larger itemsets by intersecting TID sets\n",
    "                # Create a new dictionary of items with intersected TID sets\n",
    "                new_items = {\n",
    "                    other_item: other_tids & tids\n",
    "                    for other_item, other_tids in items.items()\n",
    "                    if other_item > item  # Avoid duplicates\n",
    "                }\n",
    "                \n",
    "                dfs(new_itemset, new_items, k + 1)\n",
    "    \n",
    "    # Start DFS for each item in the vertical format\n",
    "    dfs(set(), item_tids, 1)\n",
    "    \n",
    "    return frequent_itemsets\n",
    "\n",
    "# Example Usage\n",
    "transactions = df1.apply(lambda row: row.dropna().tolist(), axis=1).tolist()\n",
    "min_support = 0.02\n",
    "frequent_itemsets = eclat(transactions, min_support)\n",
    "\n",
    "# Cleaned frequent itemsets\n",
    "frequent_itemsets_cleaned = [itemset for itemset, support in frequent_itemsets]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "96e3f170-90c7-4ef0-9a9e-7c5e90783eec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'burgers'}, 0.0872),\n",
       " ({'burgers', 'eggs'}, 0.0288),\n",
       " ({'burgers', 'mineral water'}, 0.0244),\n",
       " ({'burgers', 'french fries'}, 0.022),\n",
       " ({'burgers', 'spaghetti'}, 0.021466666666666665),\n",
       " ({'meatballs'}, 0.020933333333333335),\n",
       " ({'eggs'}, 0.17973333333333333),\n",
       " ({'eggs', 'mineral water'}, 0.05093333333333333),\n",
       " ({'eggs', 'milk'}, 0.0308),\n",
       " ({'eggs', 'green tea'}, 0.025466666666666665)]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequent_itemsets[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e85b0f6c-e474-4f18-aaf4-cb1c7336a1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Improvement\n",
    "from collections import defaultdict\n",
    "\n",
    "# Convert transactions into vertical format\n",
    "def create_vertical_format(transactions):\n",
    "    item_tids = defaultdict(set)\n",
    "    for tid, transaction in enumerate(transactions):\n",
    "        for item in transaction:\n",
    "            item_tids[item].add(tid)\n",
    "    return item_tids\n",
    "\n",
    "# Eclat algorithm to find frequent itemsets\n",
    "def eclat(transactions, min_support):\n",
    "    # Convert transactions to vertical format\n",
    "    item_tids = create_vertical_format(transactions)\n",
    "    n_transactions = len(transactions)\n",
    "    frequent_itemsets = []\n",
    "\n",
    "    # Function to calculate support based on TID sets\n",
    "    def get_support(tid_set):\n",
    "        return len(tid_set) / n_transactions\n",
    "\n",
    "    # Depth-first search (DFS) function for mining itemsets\n",
    "    def extend_itemset(prefix, prefix_tid_set, candidates):\n",
    "        # Iterate through candidates in decreasing order of support\n",
    "        for item, tids in sorted(candidates.items(), key=lambda x: -len(x[1])):\n",
    "            # Create the new candidate itemset\n",
    "            new_itemset = prefix | {item}\n",
    "            new_tid_set = prefix_tid_set & tids  # Transaction cover (intersection)\n",
    "            support = get_support(new_tid_set)\n",
    "\n",
    "            # Retain the itemset if it meets the minimum support threshold\n",
    "            if support >= min_support:\n",
    "                frequent_itemsets.append((new_itemset, support))\n",
    "\n",
    "                # Prune and prepare new candidates for recursive extension\n",
    "                new_candidates = {\n",
    "                    other_item: other_tids & new_tid_set\n",
    "                    for other_item, other_tids in candidates.items()\n",
    "                    if other_item > item and len(other_tids & new_tid_set) >= min_support * n_transactions\n",
    "                }\n",
    "\n",
    "                # Recursively extend the new itemset\n",
    "                extend_itemset(new_itemset, new_tid_set, new_candidates)\n",
    "\n",
    "    # Start DFS with the empty itemset\n",
    "    initial_candidates = {\n",
    "        item: tids for item, tids in item_tids.items()\n",
    "        if len(tids) >= min_support * n_transactions\n",
    "    }\n",
    "    extend_itemset(set(), set(range(n_transactions)), initial_candidates)\n",
    "\n",
    "    return frequent_itemsets\n",
    "\n",
    "# Example Usage\n",
    "transactions = df1.apply(lambda row: row.dropna().tolist(), axis=1).tolist()\n",
    "min_support = 0.02\n",
    "frequent_itemsets = eclat(transactions, min_support)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21020826-ad0c-4eb9-83a1-386178336b38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44f89c5-b7dd-4f81-a24c-7172068d5ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Re-import necessary libraries after execution state reset\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import ace_tools as tools\n",
    "\n",
    "# Given dataset\n",
    "data = {\n",
    "    'beer':     [1, 1, 1, 0, 0, 1],\n",
    "    'bread':    [0, 1, 0, 1, 1, 1],\n",
    "    'icecream': [0, 0, 1, 0, 1, 0],\n",
    "    'milk':     [1, 0, 0, 1, 1, 1],\n",
    "    'pampers':  [1, 1, 1, 0, 0, 1],\n",
    "    'pizza':    [1, 1, 1, 0, 0, 0]\n",
    "}\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Define minimum support threshold\n",
    "min_support = 3\n",
    "\n",
    "# Step 1: Calculate support for individual items (1-itemsets)\n",
    "support_count = df.sum(axis=0)\n",
    "\n",
    "# Filter frequent 1-itemsets\n",
    "frequent_1_itemsets = {item: count for item, count in support_count.items() if count >= min_support}\n",
    "\n",
    "# Step 2: Generate candidate 2-itemsets from frequent 1-itemsets\n",
    "frequent_1_items = list(frequent_1_itemsets.keys())\n",
    "candidate_2_itemsets = list(itertools.combinations(frequent_1_items, 2))\n",
    "\n",
    "# Calculate support for 2-itemsets\n",
    "support_2_itemsets = {}\n",
    "for itemset in candidate_2_itemsets:\n",
    "    support_2_itemsets[itemset] = df[list(itemset)].all(axis=1).sum()\n",
    "\n",
    "# Filter frequent 2-itemsets\n",
    "frequent_2_itemsets = {itemset: count for itemset, count in support_2_itemsets.items() if count >= min_support}\n",
    "\n",
    "# Step 3: Generate candidate 3-itemsets from frequent 2-itemsets\n",
    "frequent_2_items = list(frequent_2_itemsets.keys())\n",
    "candidate_3_itemsets = list(itertools.combinations(set(itertools.chain(*frequent_2_items)), 3))\n",
    "\n",
    "# Calculate support for 3-itemsets\n",
    "support_3_itemsets = {}\n",
    "for itemset in candidate_3_itemsets:\n",
    "    support_3_itemsets[itemset] = df[list(itemset)].all(axis=1).sum()\n",
    "\n",
    "# Filter frequent 3-itemsets\n",
    "frequent_3_itemsets = {itemset: count for itemset, count in support_3_itemsets.items() if count >= min_support}\n",
    "\n",
    "# Combine frequent itemsets\n",
    "frequent_itemsets = {**frequent_1_itemsets, **frequent_2_itemsets, **frequent_3_itemsets}\n",
    "\n",
    "# Display results\n",
    "df_frequent_itemsets = pd.DataFrame.from_dict(frequent_itemsets, orient='index', columns=['Support'])\n",
    "tools.display_dataframe_to_user(name=\"Frequent Itemsets\", dataframe=df_frequent_itemsets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eccdd97-d1d1-4847-8f74-d33c5cb04d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing Eclat algorithm for frequent itemset mining\n",
    "\n",
    "# Convert dataset to transaction ID (TID) format for Eclat\n",
    "tid_lists = {item: set(df[df[item] == 1].index) for item in df.columns}\n",
    "\n",
    "# Define a function for Eclat recursion\n",
    "def eclat(prefix, tid_list, items, min_support):\n",
    "    \"\"\"\n",
    "    Recursive function to generate frequent itemsets using Eclat.\n",
    "    \"\"\"\n",
    "    frequent_itemsets = {}\n",
    "    \n",
    "    for i in range(len(items)):\n",
    "        item = items[i]\n",
    "        new_tid_list = tid_list & tid_lists[item]  # Compute transaction intersection\n",
    "        support = len(new_tid_list)\n",
    "        \n",
    "        if support >= min_support:\n",
    "            new_itemset = prefix + (item,)\n",
    "            frequent_itemsets[new_itemset] = support\n",
    "            frequent_itemsets.update(eclat(new_itemset, new_tid_list, items[i+1:], min_support))\n",
    "    \n",
    "    return frequent_itemsets\n",
    "\n",
    "# Run Eclat algorithm\n",
    "eclat_frequent_itemsets = eclat((), set(range(len(df))), list(tid_lists.keys()), min_support)\n",
    "\n",
    "# Convert to DataFrame for display\n",
    "df_eclat_itemsets = pd.DataFrame.from_dict(eclat_frequent_itemsets, orient='index', columns=['Support'])\n",
    "tools.display_dataframe_to_user(name=\"Eclat Frequent Itemsets\", dataframe=df_eclat_itemsets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad375507-9137-4fbd-b187-12ca853cf3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "######## eclat manually\n",
    "\n",
    "# Implementing the Eclat algorithm manually\n",
    "\n",
    "# Function to find frequent itemsets using Eclat\n",
    "def eclat(transactions, min_support=0.05):\n",
    "    item_sets = defaultdict(set)\n",
    "    total_transactions = len(transactions)\n",
    "    \n",
    "    # Create item transaction sets\n",
    "    for tid, transaction in enumerate(transactions):\n",
    "        for item in transaction:\n",
    "            item_sets[item].add(tid)\n",
    "\n",
    "    # Calculate support for each itemset\n",
    "    frequent_itemsets = {item: len(tids) / total_transactions for item, tids in item_sets.items() if len(tids) / total_transactions >= min_support}\n",
    "\n",
    "    return frequent_itemsets\n",
    "\n",
    "# Run Eclat on the dataset\n",
    "min_support = 0.05  # Minimum support threshold\n",
    "frequent_itemsets_eclat = eclat(transactions_new, min_support)\n",
    "\n",
    "# Convert to DataFrame\n",
    "frequent_items_eclat_df = pd.DataFrame(frequent_itemsets_eclat.items(), columns=['Item', 'Support'])\n",
    "frequent_items_eclat_df = frequent_items_eclat_df.sort_values(by='Support', ascending=False)\n",
    "\n",
    "# Display the frequent itemsets found using Eclat\n",
    "tools.display_dataframe_to_user(name=\"Frequent Itemsets (Eclat)\", dataframe=frequent_items_eclat_df)\n",
    "\n",
    "\n",
    "##### with libraries\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "# Function to find frequent itemsets using Eclat with pairwise transactions\n",
    "def eclat_library_based(transactions, min_support=0.05):\n",
    "    item_sets = defaultdict(set)\n",
    "    total_transactions = len(transactions)\n",
    "    \n",
    "    # Create item transaction sets\n",
    "    for tid, transaction in enumerate(transactions):\n",
    "        for item in transaction:\n",
    "            item_sets[item].add(tid)\n",
    "\n",
    "    # Generate itemsets of size 2 (pairwise combinations)\n",
    "    frequent_itemsets = {item: len(tids) / total_transactions for item, tids in item_sets.items() if len(tids) / total_transactions >= min_support}\n",
    "    \n",
    "    # Generate larger itemsets (Eclat works recursively)\n",
    "    pair_sets = defaultdict(set)\n",
    "    for (item1, tids1), (item2, tids2) in combinations(item_sets.items(), 2):\n",
    "        common_tids = tids1 & tids2  # Intersection of transactions containing both items\n",
    "        if len(common_tids) / total_transactions >= min_support:\n",
    "            pair_sets[(item1, item2)] = common_tids\n",
    "\n",
    "    # Convert to DataFrame for display\n",
    "    frequent_pairsets = {pair: len(tids) / total_transactions for pair, tids in pair_sets.items()}\n",
    "    \n",
    "    return frequent_itemsets, frequent_pairsets\n",
    "\n",
    "# Run Eclat on the dataset\n",
    "min_support = 0.05  # Minimum support threshold\n",
    "frequent_itemsets_eclat, frequent_pairsets_eclat = eclat_library_based(transactions_new, min_support)\n",
    "\n",
    "# Convert single item frequent sets to DataFrame\n",
    "frequent_items_eclat_df = pd.DataFrame(frequent_itemsets_eclat.items(), columns=['Item', 'Support'])\n",
    "frequent_items_eclat_df = frequent_items_eclat_df.sort_values(by='Support', ascending=False)\n",
    "\n",
    "# Convert frequent pairs to DataFrame\n",
    "frequent_pairsets_eclat_df = pd.DataFrame(frequent_pairsets_eclat.items(), columns=['Item Pair', 'Support'])\n",
    "frequent_pairsets_eclat_df = frequent_pairsets_eclat_df.sort_values(by='Support', ascending=False)\n",
    "\n",
    "# Display the frequent itemsets found using Eclat\n",
    "tools.display_dataframe_to_user(name=\"Frequent Itemsets (Eclat - Single Items)\", dataframe=frequent_items_eclat_df)\n",
    "\n",
    "# Display the frequent item pairs found using Eclat\n",
    "tools.display_dataframe_to_user(name=\"Frequent Itemsets (Eclat - Pairs)\", dataframe=frequent_pairsets_eclat_df)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
